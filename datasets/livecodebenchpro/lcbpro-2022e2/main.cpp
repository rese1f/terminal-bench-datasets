#include <iostream>
#include <vector>
#include <numeric> // Required for std::iota
#include <tuple> // Required for std::tuple
#include <vector> // Standard library vector

// Modular exponentiation function
// Computes (base^exp) % modulus
// Uses binary exponentiation (also known as exponentiation by squaring)
long long power_mod(long long base, long long exp, long long modulus) {
    long long res = 1;
    base %= modulus;
    // Handle base=0 case. If exp=0, 0^0 is typically 1. If exp > 0, 0^exp is 0.
    // In this problem, base is 2, so base=0 case is not relevant.
    // But handling it generally:
    if (base == 0) return (exp == 0) ? 1 : 0; 
    while (exp > 0) {
        // If exp is odd, multiply base with result
        if (exp % 2 == 1) res = (res * base) % modulus;
        // Square the base and halve the exponent
        base = (base * base) % modulus;
        exp /= 2;
    }
    return res;
}

// Define maximum number of nodes for DSU parent and diff arrays
// The total number of nodes is n + m. Constraints state n, m <= 10^5.
// So n+m can be up to 2*10^5. Use 1-based indexing for nodes.
const int MAX_N_PLUS_M = 200005; 

// Disjoint Set Union (DSU) structure definition
// This DSU variant maintains XOR differences along paths using path compression.
struct DSU {
    std::vector<int> parent;
    // diff[i] stores the XOR sum difference between node i and its parent: value[i] ^ value[parent[i]]
    std::vector<int> diff; 

    // Default constructor needed for global array initialization.
    DSU(int N = 0) { 
        if (N > 0) {
           init(N); // Initialize if size is provided
        }
    }
    
    // Initialize or reset DSU structure for N nodes
    void init(int N) {
         // Resize vectors if needed. Using resize ensures capacity is at least N+1.
         if (parent.size() < N + 1) {
             parent.resize(N + 1);
             diff.resize(N + 1);
         }
         // Initialize parent[i] = i for nodes 1 to N
         std::iota(parent.begin() + 1, parent.begin() + N + 1, 1);
         // Initialize diff[i] = 0 for nodes 1 to N
         std::fill(diff.begin() + 1, diff.begin() + N + 1, 0);
    }

    // Find operation with path compression and path XOR sum calculation
    // Returns {root, path_XOR_sum}, where path_XOR_sum is value[i] ^ value[root]
    std::pair<int, int> find(int i) {
        // Base case: if i is the root of its component
        if (parent[i] == i) {
            return {i, 0}; 
        }
        // Recursive call to find the root of the parent
        // Path compression happens after the recursive call returns
        auto [root, root_diff] = find(parent[i]); 
        
        // Update diff[i]: This now represents value[i] ^ value[root]
        // The logic: The current diff[i] = value[i] ^ value[parent[i]].
        // The returned root_diff = value[parent[i]] ^ value[root].
        // XORing these gives (value[i] ^ value[parent[i]]) ^ (value[parent[i]] ^ value[root]) = value[i] ^ value[root].
        diff[i] ^= root_diff; 
        // Path compression: point i directly to the root
        parent[i] = root; 
        return {root, diff[i]};
    }

    // Unite operation
    // Merges the sets containing nodes u and v based on the constraint value[u] ^ value[v] = val
    // Returns true if a merge occurred, false otherwise (if already in same component)
    // Sets inconsistent_flag to true if the constraint conflicts with existing structure in the component
    bool unite(int u, int v, int val, bool& inconsistent_flag) {
        // Find roots and path XOR sums for u and v
        auto [root_u, diff_u] = find(u); // diff_u = value[u] ^ value[root_u]
        auto [root_v, diff_v] = find(v); // diff_v = value[v] ^ value[root_v]

        // If u and v are in different components, merge them
        if (root_u != root_v) {
            // Merge root_v into root_u (standard practice often involves rank/size, but simple merge works)
            parent[root_v] = root_u;
            // Calculate the required diff for the new parent link: diff[root_v] = value[root_v] ^ value[parent[root_v]] = value[root_v] ^ value[root_u]
            // We know: value[u] ^ value[v] = val (given constraint)
            // Substituting path XOR sums: (value[root_u] ^ diff_u) ^ (value[root_v] ^ diff_v) = val
            // Rearranging to find value[root_u] ^ value[root_v]: value[root_u] ^ value[root_v] = val ^ diff_u ^ diff_v
            diff[root_v] = val ^ diff_u ^ diff_v;
            return true; // Merge successful
        } else {
            // If u and v are already in the same component, check for consistency
            // The existing structure implies: value[u] ^ value[v] = diff_u ^ diff_v
            // The new constraint requires: value[u] ^ value[v] = val
            // Check if these are compatible
            if ((diff_u ^ diff_v) != val) {
                // If not compatible, mark this bit position as inconsistent
                inconsistent_flag = true; 
            }
            return false; // No merge happened
        }
    }
};

// Global array of DSU structures, one for each of the 30 bits
DSU dsu_arr[30]; 
// Global array to track inconsistency for each bit position
bool inconsistent[30]; 
// Global counter for total successful merges across all bit positions
long long total_merges = 0;
// Global counter for the number of bit positions found to be inconsistent
int num_inconsistent = 0;

// Function to add a constraint (r, c, v) to the system
// Updates all 30 DSU structures based on the bits of v
void add_constraint(int r, int c, int v, int n) {
    int node_u = r; // Node index for row r (1-based)
    int node_v = n + c; // Node index for column c (1-based, shifted by n)
    
    // Process the constraint for each bit position from 0 to 29
    for (int b = 0; b < 30; ++b) {
        // If this bit position is already known inconsistent, skip further processing for it
        if (inconsistent[b]) continue; 
        
        int bit_val = (v >> b) & 1; // Extract the b-th bit of v
        // Temporary flag to detect inconsistency from the current unite call
        bool current_inconsistency_detected = false; 
        
        // Perform the unite operation for the b-th bit DSU structure
        bool merged = dsu_arr[b].unite(node_u, node_v, bit_val, current_inconsistency_detected);

        // If inconsistency was detected by unite
        if (current_inconsistency_detected) {
             // Check if this is the first time inconsistency is detected for bit b
             if (!inconsistent[b]) { 
                 inconsistent[b] = true; // Mark bit b as inconsistent
                 num_inconsistent++; // Increment the global count of inconsistent bits
             }
        } else if (merged) {
             // If the unite operation resulted in a merge (sets were different)
            total_merges++; // Increment the global count of successful merges
        }
        // If sets were already the same and consistent, do nothing.
    }
}

int main() {
    // Optimize C++ standard streams
    std::ios_base::sync_with_stdio(false);
    std::cin.tie(NULL);

    int t; // Number of test cases
    std::cin >> t;
    while (t--) {
        int n, m, k, q; // Grid dimensions, initial fixed cells, number of updates
        std::cin >> n >> m >> k >> q;

        // Store initial constraints
        std::vector<std::tuple<int, int, int>> initial_constraints(k);
        for (int i = 0; i < k; ++i) {
            std::cin >> std::get<0>(initial_constraints[i]) >> std::get<1>(initial_constraints[i]) >> std::get<2>(initial_constraints[i]);
        }
        
        // Store updates
        std::vector<std::tuple<int, int, int>> updates(q);
        for (int i = 0; i < q; ++i) {
            std::cin >> std::get<0>(updates[i]) >> std::get<1>(updates[i]) >> std::get<2>(updates[i]);
        }

        int N_nodes = n + m; // Total nodes in DSU (n rows + m columns)
        // Initialize/Reset global state for the current test case
        for(int b=0; b<30; ++b) {
            dsu_arr[b].init(N_nodes); // Initialize each DSU structure
            inconsistent[b] = false; // Reset inconsistency flags
        }
        total_merges = 0; // Reset total merges count
        num_inconsistent = 0; // Reset inconsistent bits count

        // Process the initial k constraints
        for (int i = 0; i < k; ++i) {
            add_constraint(std::get<0>(initial_constraints[i]), std::get<1>(initial_constraints[i]), std::get<2>(initial_constraints[i]), n);
        }

        // Define moduli for calculations
        long long M = 1000000000 + 6; // Modulus for the exponent (phi(P))
        long long P = 1000000000 + 7; // Modulus for the final answer

        // Loop through states: initial state (i=0) and after each update (i=1 to q)
        for (int i = 0; i <= q; ++i) {
             // If any bit position is inconsistent, no valid grid completions exist
             if (num_inconsistent > 0) {
                 std::cout << 0 << "\n";
             } else {
                 // Calculate the exponent E - 30
                 // Total components E = sum(Cb) = sum(N_nodes - Mb) = 30*N_nodes - sum(Mb) = 30*N_nodes - total_merges
                 long long exp_val = 30LL * N_nodes - total_merges - 30;
                 
                 // Compute the exponent modulo M = 10^9 + 6
                 // Ensure the result is non-negative using (exp_val % M + M) % M
                 long long mod_exp = (exp_val % M + M) % M;
                 
                 // Compute 2^mod_exp mod P and print the result
                 std::cout << power_mod(2, mod_exp, P) << "\n";
             }
             
             // If it's not the last iteration, apply the i-th update for the next state
             if (i < q) {
                 add_constraint(std::get<0>(updates[i]), std::get<1>(updates[i]), std::get<2>(updates[i]), n);
             }
        }
    }
    return 0;
}